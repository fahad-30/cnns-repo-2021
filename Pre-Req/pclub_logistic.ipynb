{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes2.csv')\n",
    "\n",
    "#training data (80%)\n",
    "train = data.sample(frac = 0.8)\n",
    "X_train = train.iloc[:,:8]\n",
    "y_train = train.iloc[:,8]\n",
    "\n",
    "#testing data (20%)\n",
    "test = data.loc[data.index.difference(train.index)]\n",
    "X_test = test.iloc[:,:8]\n",
    "y_test = test.iloc[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg:\n",
    "    def __init__(self,lr,epochs):\n",
    "        self.lr = lr;\n",
    "        self.epochs = epochs\n",
    "        self.teetha = None \n",
    "        self.bias = None\n",
    "        self.loss = np.zeros(epochs//100 + 1)\n",
    "        self.acc = np.zeros(epochs//100 + 1)\n",
    "        \n",
    "    #fitting for the LR model\n",
    "    def fit(self,X,y):\n",
    "        samples, features = X.shape\n",
    "        self.teetha = np.zeros(features)\n",
    "        self.bias = 0\n",
    "\n",
    "        #gradient descent method\n",
    "        for i in range(self.epochs+1):\n",
    "            #logistic \n",
    "            linear = (X @ self.teetha) + self.bias\n",
    "            y_pred = self._sigmoid(linear)\n",
    "            \n",
    "            #loss rates\n",
    "            dt = (1/samples) * (X.T @ (y_pred-y))\n",
    "            db = (1/samples) * np.sum(y_pred-y)\n",
    "            \n",
    "            #updating values\n",
    "            self.teetha -= self.lr * dt\n",
    "            self.bias -= self.lr * db\n",
    "            \n",
    "            #printing training after every 100 epochs\n",
    "            if  i%100 == 0:\n",
    "                \n",
    "                #loss\n",
    "                self.loss[i//100]  = (1/samples)*(((-y).T @ np.log(y_pred))-((1-y).T @ np.log(1-y_pred)))\n",
    "                \n",
    "                #accuracy\n",
    "                self.acc[i//100] = (1/samples) * np.sum(abs(self.prediction(X)==y))\n",
    "                \n",
    "                #\n",
    "                print('Epoch',i,': (Loss: ',self.loss[i//100],',Correctness: ',format(self.acc[i//100],\"0.3f\"),')')\n",
    "        \n",
    "        \n",
    "    #prediction\n",
    "    def prediction(self,X):\n",
    "        linear = (X @ self.teetha)+self.bias\n",
    "        y_pred = self._sigmoid(linear)\n",
    "        y_binary = [1 if i>0.5 else 0 for i in y_pred]\n",
    "        \n",
    "        return y_binary\n",
    "    \n",
    "    #to \n",
    "    def _sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Variables and Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : (Loss:  0.6931471805599455 ,Correctness:  0.629 )\n",
      "Epoch 100 : (Loss:  0.6697867690333147 ,Correctness:  0.630 )\n",
      "Epoch 200 : (Loss:  0.6632670113794674 ,Correctness:  0.634 )\n",
      "Epoch 300 : (Loss:  0.6581967533152298 ,Correctness:  0.632 )\n",
      "Epoch 400 : (Loss:  0.6541696669160761 ,Correctness:  0.635 )\n",
      "Epoch 500 : (Loss:  0.6509551859026079 ,Correctness:  0.638 )\n",
      "Epoch 600 : (Loss:  0.6483758524593684 ,Correctness:  0.638 )\n",
      "Epoch 700 : (Loss:  0.6462943970815688 ,Correctness:  0.642 )\n",
      "Epoch 800 : (Loss:  0.6446046698852304 ,Correctness:  0.643 )\n",
      "Epoch 900 : (Loss:  0.6432244554772969 ,Correctness:  0.650 )\n",
      "Epoch 1000 : (Loss:  0.6420898910432337 ,Correctness:  0.648 )\n",
      "Epoch 1100 : (Loss:  0.6411511854555644 ,Correctness:  0.647 )\n",
      "Epoch 1200 : (Loss:  0.640369357275107 ,Correctness:  0.647 )\n",
      "Epoch 1300 : (Loss:  0.6397137547631236 ,Correctness:  0.651 )\n",
      "Epoch 1400 : (Loss:  0.6391601695726656 ,Correctness:  0.656 )\n",
      "Epoch 1500 : (Loss:  0.6386893988225444 ,Correctness:  0.660 )\n",
      "Epoch 1600 : (Loss:  0.6382861453225753 ,Correctness:  0.658 )\n",
      "Epoch 1700 : (Loss:  0.637938173059393 ,Correctness:  0.661 )\n",
      "Epoch 1800 : (Loss:  0.6376356558549552 ,Correctness:  0.661 )\n",
      "Epoch 1900 : (Loss:  0.6373706727251968 ,Correctness:  0.663 )\n",
      "Epoch 2000 : (Loss:  0.6371368151064373 ,Correctness:  0.663 )\n",
      "Epoch 2100 : (Loss:  0.6369288797698274 ,Correctness:  0.666 )\n",
      "Epoch 2200 : (Loss:  0.6367426276756502 ,Correctness:  0.664 )\n",
      "Epoch 2300 : (Loss:  0.6365745938081219 ,Correctness:  0.664 )\n",
      "Epoch 2400 : (Loss:  0.6364219366075459 ,Correctness:  0.666 )\n",
      "Epoch 2500 : (Loss:  0.6362823182972448 ,Correctness:  0.664 )\n",
      "Epoch 2600 : (Loss:  0.6361538094204938 ,Correctness:  0.664 )\n",
      "Epoch 2700 : (Loss:  0.636034812428434 ,Correctness:  0.664 )\n",
      "Epoch 2800 : (Loss:  0.63592400031911 ,Correctness:  0.664 )\n",
      "Epoch 2900 : (Loss:  0.6358202672125773 ,Correctness:  0.664 )\n",
      "Epoch 3000 : (Loss:  0.6357226884256539 ,Correctness:  0.663 )\n",
      "Epoch 3100 : (Loss:  0.6356304881327767 ,Correctness:  0.663 )\n",
      "Epoch 3200 : (Loss:  0.635543013104165 ,Correctness:  0.663 )\n",
      "Epoch 3300 : (Loss:  0.6354597113271733 ,Correctness:  0.663 )\n",
      "Epoch 3400 : (Loss:  0.6353801145623931 ,Correctness:  0.663 )\n",
      "Epoch 3500 : (Loss:  0.6353038240786765 ,Correctness:  0.666 )\n",
      "Epoch 3600 : (Loss:  0.6352304989628414 ,Correctness:  0.666 )\n",
      "Epoch 3700 : (Loss:  0.6351598465195574 ,Correctness:  0.666 )\n",
      "Epoch 3800 : (Loss:  0.6350916143718377 ,Correctness:  0.666 )\n",
      "Epoch 3900 : (Loss:  0.635025583948069 ,Correctness:  0.668 )\n",
      "Epoch 4000 : (Loss:  0.6349615651017433 ,Correctness:  0.668 )\n",
      "Epoch 4100 : (Loss:  0.6348993916582772 ,Correctness:  0.668 )\n",
      "Epoch 4200 : (Loss:  0.6348389177219859 ,Correctness:  0.668 )\n",
      "Epoch 4300 : (Loss:  0.6347800146074156 ,Correctness:  0.668 )\n",
      "Epoch 4400 : (Loss:  0.6347225682843525 ,Correctness:  0.668 )\n",
      "Epoch 4500 : (Loss:  0.6346664772461265 ,Correctness:  0.669 )\n",
      "Epoch 4600 : (Loss:  0.6346116507272845 ,Correctness:  0.669 )\n",
      "Epoch 4700 : (Loss:  0.6345580072100679 ,Correctness:  0.669 )\n",
      "Epoch 4800 : (Loss:  0.634505473169995 ,Correctness:  0.671 )\n",
      "Epoch 4900 : (Loss:  0.6344539820197107 ,Correctness:  0.673 )\n",
      "Epoch 5000 : (Loss:  0.634403473217493 ,Correctness:  0.673 )\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "epochs = 5000\n",
    "\n",
    "#initializing model\n",
    "model = LogReg(lr,epochs)\n",
    "\n",
    "#model fitting/training\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction and Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 / 154 ( 74.68 %)\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "y_pred = model.prediction(X_test)\n",
    "\n",
    "#accuracy calculation\n",
    "corr = np.sum(y_pred==y_test)\n",
    "total = len(y_test)\n",
    "\n",
    "print(corr,'/',total,'(',format((corr/total)*100,\"0.2f\"),'%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Error and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-079ec09d0510>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ko-'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmarkersize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rD-'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmarkersize\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(range(0,epochs+1,100),model.loss,'ko-',markersize=3)\n",
    "plt.xlabel('Epochs')\n",
    "plt.plot(range(0,epochs+1,100),model.acc,'rD-',markersize= 3)\n",
    "plt.legend(['Loss','Accuracy'])\n",
    "\n",
    "# plt.savefig(\"error_acc_plot.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015625"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import process_time\n",
    "\n",
    "list = [i for i in range(10000)]\n",
    "\n",
    "start = process_time()\n",
    "\n",
    "list = [i+2 for i in list]\n",
    "\n",
    "end = process_time()\n",
    "\n",
    "round(end-start,6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
